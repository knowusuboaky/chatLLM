[{"path":"https://knowusuboaky.github.io/chatLLM/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Kwadwo Daddy Nyame Owusu Boakye Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kwadwo Daddy Nyame Owusu Boakye. Author, maintainer.","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Owusu Boakye K (2025). chatLLM: Flexible Interface 'LLM' API Interactions. R package version 0.1.1, https://github.com/knowusuboaky/chatLLM.","code":"@Manual{,   title = {chatLLM: A Flexible Interface for 'LLM' API Interactions},   author = {Kwadwo Daddy Nyame {Owusu Boakye}},   year = {2025},   note = {R package version 0.1.1},   url = {https://github.com/knowusuboaky/chatLLM}, }"},{"path":[]},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Flexible Interface for LLM API Interactions","text":"chatLLM R package provides unified flexible interface interacting popular Large Language Model (LLM) providers OpenAI, Groq, Anthropic. Features include: üîÅ Seamless provider switching üó£ Multi-message conversations üîÑ Retries + backoff üîå Extendable parameters üõ† Test using .post_func","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Flexible Interface for LLM API Interactions","text":"","code":"install.packages(\"chatLLM\")"},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"development-version","dir":"","previous_headings":"","what":"Development version","title":"A Flexible Interface for LLM API Interactions","text":"get latest features bug fixes, can install development version chatLLM GitHub: See full function reference package website details.","code":"# If needed install.packages(\"remotes\")  remotes::install_github(\"knowusuboaky/chatLLM\")"},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"environment-setup","dir":"","previous_headings":"","what":"Environment Setup","title":"A Flexible Interface for LLM API Interactions","text":"","code":"Sys.setenv(OPENAI_API_KEY    = \"your-openai-api-key\") Sys.setenv(GROQ_API_KEY      = \"your-groq-api-key\") Sys.setenv(ANTHROPIC_API_KEY = \"your-anthropic-api-key\")"},{"path":[]},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"id_1-simple-prompt-call","dir":"","previous_headings":"Usage","what":"1. Simple Prompt Call","title":"A Flexible Interface for LLM API Interactions","text":"","code":"response <- call_llm(   prompt = \"Who is messi?\",   provider = \"openai\",   max_tokens = 500,   n_tries = 3,   backoff = 2 ) response #> [1] \"Lionel Messi is an Argentine professional footballer who plays as a forward for Paris Saint-Germain and the Argentina national team. #> He is widely considered one of the greatest footballers of all time, having won numerous awards and accolades throughout his career. #> Messi is known for his incredible dribbling skills, vision, and goal-scoring ability.\"  cat(response) #> Lionel Messi is an Argentine professional footballer who plays as a forward for Paris Saint-Germain and the Argentina national team. #> He is widely considered one of the greatest footballers of all time, having won numerous awards and accolades throughout his career. #> Messi is known for his incredible dribbling skills, vision, and goal-scoring ability."},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"id_2-multi-message-conversation","dir":"","previous_headings":"Usage","what":"2. Multi-Message Conversation","title":"A Flexible Interface for LLM API Interactions","text":"","code":"conv <- list(   list(role = \"system\", content = \"You are a helpful assistant.\"),   list(role = \"user\", content = \"Explain recursion in R.\") ) response <- call_llm(   messages = conv,   provider = \"openai\",   max_tokens = 200,   presence_penalty = 0.2,   frequency_penalty = 0.1,   top_p = 0.95 ) response #> [1] \"Recursion is a programming technique where a function calls itself in order to solve a problem. #> In R, a recursive function is defined similarly to any other function, but within the function body, there is a call to the same function. #> This continues until a base case is reached, at which point the recursion unwinds and results are returned. #> #> Here is an example of a recursive factorial function in R: #> #> factorial_recursive <- function(n) { #>   if (n == 0) return(1) #>   n * factorial_recursive(n - 1) #> } #> #> factorial_recursive(5)  # 120\"  cat(response) #> Recursion is a programming technique where a function calls itself in order to solve a problem. #> In R, a recursive function is defined similarly to any other function, but within the function body, there is a call to the same function. #> This continues until a base case is reached, at which point the recursion unwinds and results are returned. #> #> Here is an example of a recursive factorial function in R: #> #> factorial_recursive <- function(n) { #>   if (n == 0) return(1) #>   n * factorial_recursive(n - 1) #> } #> #> factorial_recursive(5)  # 120"},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"A Flexible Interface for LLM API Interactions","text":"Please open issue GitHub run bugs feature requests.","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"A Flexible Interface for LLM API Interactions","text":"MIT ¬© Kwadwo Daddy Nyame Owusu Boakye","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"A Flexible Interface for LLM API Interactions","text":"Inspired projects like RAGFlowChainR powered R open-source community. Enjoy chatting LLMs!","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/reference/call_llm.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a Large Language Model with optional retries & extra parameters ‚Äî call_llm","title":"Call a Large Language Model with optional retries & extra parameters ‚Äî call_llm","text":"Call Large Language Model optional retries & extra parameters","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/reference/call_llm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a Large Language Model with optional retries & extra parameters ‚Äî call_llm","text":"","code":"call_llm(   prompt = NULL,   messages = NULL,   provider = c(\"openai\", \"groq\", \"anthropic\"),   model = NULL,   temperature = 0.7,   max_tokens = 1000,   api_key = NULL,   n_tries = 3,   backoff = 2,   endpoint_url = NULL,   ...,   .post_func = httr::POST )"},{"path":"https://knowusuboaky.github.io/chatLLM/reference/call_llm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a Large Language Model with optional retries & extra parameters ‚Äî call_llm","text":"prompt (character) single user prompt. `messages` provided, prompt appended user message (optional). messages (list) list message objects, list(role, content). provider (character) One \"openai\", \"groq\", \"anthropic\". model (character) model name. Defaults known model per provider. temperature (numeric) Sampling temperature (0 ~2). max_tokens (integer) Maximum number tokens generate. api_key (character) API key. NULL, uses environment variable. n_tries (integer) Number attempts retry failure. backoff (numeric) Seconds wait retries. endpoint_url (character) Base URL provider. NULL, uses default given provider. ... Additional parameters appended request body. .post_func (function) (Internal) Function perform POST requests. Defaults httr::POST.","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/reference/call_llm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a Large Language Model with optional retries & extra parameters ‚Äî call_llm","text":"(character) text completion chosen model.","code":""},{"path":"https://knowusuboaky.github.io/chatLLM/reference/call_llm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a Large Language Model with optional retries & extra parameters ‚Äî call_llm","text":"","code":"if (FALSE) { # \\dontrun{ response <- call_llm(   prompt = \"Hello, how are you?\",   provider = \"openai\",   max_tokens = 50,   n_tries = 3,   backoff = 2 ) cat(response)  conv <- list(   list(role = \"system\", content = \"You are a helpful assistant.\"),   list(role = \"user\",   content = \"Explain recursion in R.\") ) response <- call_llm(   messages = conv,   provider = \"openai\",   max_tokens = 200,   presence_penalty = 0.2,   frequency_penalty = 0.1,   top_p = 0.95,   stop = c(\"###\") ) cat(response) } # }"},{"path":[]},{"path":"https://knowusuboaky.github.io/chatLLM/news/index.html","id":"new-features-0-1-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"chatLLM 0.1.2 (Upcoming Release ‚Äì May 2025)","text":"DeepSeek Integration Added support DeepSeek language model. can now use DeepSeek LLM backend via chatLLM::use_deepseek(). brings greater flexibility expanded model support chatLLM ecosystem.","code":""}]
